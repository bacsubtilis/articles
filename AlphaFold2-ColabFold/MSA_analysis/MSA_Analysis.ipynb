{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2abc972-4709-4f74-897d-0624033901cf",
   "metadata": {},
   "source": [
    "## Analysis of the species distribution in MSA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b305a9-0dc6-4a80-9d62-c614b2c645e3",
   "metadata": {},
   "source": [
    "### 1. Get the species names from the MSA, based on the downloaded UniRef100 gzipped file, and store them in an sqlite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7df5503-4493-4721-918a-7a7a9458a102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing MSA file: 100%|██████████| 14175/14175 [00:00<00:00, 1907847.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6423 UniRef IDs in MSA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import sqlite3\n",
    "import re\n",
    "from tqdm import tqdm  # This is just for the progress bar (optional: install it with `pip install tqdm`)\n",
    "\n",
    "# Get MSA file from user input\n",
    "msa_file = input(\"Enter the path to your MSA file (.a3m file): \").strip()\n",
    "\n",
    "# Collect UniRef IDs from our MSA\n",
    "uniref_ids_in_msa = set()\n",
    "\n",
    "try:\n",
    "    # First, count the total lines for the progress bar\n",
    "    with open(msa_file, \"r\") as f:\n",
    "        total_lines = sum(1 for _ in f)\n",
    "    \n",
    "    # Now process with progress bar\n",
    "    with open(msa_file, \"r\") as f:\n",
    "        for line in tqdm(f, total=total_lines, desc=\"Processing MSA file\"):\n",
    "            # Valid IDs start with the below prefix\n",
    "            if line.startswith(\">UniRef100_\"):\n",
    "                uniref_id = line.strip()[1:].split()[0]  # This will extract UniRef100_A0A1B0GTX2 for example\n",
    "                uniref_ids_in_msa.add(uniref_id)\n",
    "\n",
    "    print(f\"Found {len(uniref_ids_in_msa)} UniRef IDs in MSA.\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{msa_file}' not found. Please check the path and try again.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while processing the file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c856c735-3eae-44b0-b859-24f0a695641a",
   "metadata": {},
   "source": [
    "### 2. Build the lookup table (SQLite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d6a66b-069c-42c2-a784-6e8a7dfb0ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning UniRef100.fasta.gz: 3596596416it [22:08, 2706381.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found species for 5983/6423 UniRef IDs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_user_paths():\n",
    "    \"\"\"Get database and UniRef file paths from user input\"\"\"\n",
    "    db_path = input(\"Enter the path for the SQLite database file: \").strip()\n",
    "    uniref_gz_path = input(\"Enter the path for the UniRef100 gzipped FASTA file: \").strip()\n",
    "    return db_path, uniref_gz_path\n",
    "\n",
    "# Initialise the SQLite database. SQLite file will serve as the lookup table\n",
    "def init_db(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS uniref_species (\n",
    "            uniref_id TEXT PRIMARY KEY,\n",
    "            species TEXT\n",
    "        )\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "# Get paths from user input\n",
    "db_path, uniref_gz_path = get_user_paths()\n",
    "\n",
    "# Initialise the database connection\n",
    "conn = init_db(db_path)\n",
    "\n",
    "# Scan UniRef100.fasta.gz ONLY for IDs in your MSA\n",
    "found_ids = set()\n",
    "\n",
    "def extract_species(header):\n",
    "    tax_match = re.search(r'Tax=([^=]+?)\\s+TaxID=', header)\n",
    "    if tax_match:\n",
    "        species = tax_match.group(1).strip()\n",
    "        species = re.sub(r'[\\d_]+$', '', species).strip()\n",
    "        return species or \"Unknown\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "# Stream gzip file line-by-line\n",
    "with gzip.open(uniref_gz_path, \"rt\") as f:\n",
    "    current_id = None\n",
    "    for line in tqdm(f, desc=\"Scanning UniRef100.fasta.gz\"):\n",
    "        if line.startswith(\">\"):\n",
    "            current_id = line.split()[0][1:]  # Extract UniRef100_A0A1B0GTX2\n",
    "            if current_id in uniref_ids_in_msa:\n",
    "                species = extract_species(line)\n",
    "                conn.cursor().execute(\n",
    "                    \"INSERT OR IGNORE INTO uniref_species VALUES (?, ?)\",\n",
    "                    (current_id, species)\n",
    "                )\n",
    "                found_ids.add(current_id)\n",
    "                # Early exit if all IDs are found\n",
    "                if len(found_ids) == len(uniref_ids_in_msa):\n",
    "                    break\n",
    "    conn.commit()\n",
    "\n",
    "print(f\"Found species for {len(found_ids)}/{len(uniref_ids_in_msa)} UniRef IDs.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finals-for-github",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
